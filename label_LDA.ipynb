{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "730b0a09-8eb0-4a5d-b964-09148d7c624a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['? (film)'],\n",
       " '? (also written Tanda Tanya, meaning Question Mark) is a 2011 Indonesian drama film directed by Hanung Bramantyo. It stars Revalina Sayuthi Temat, Reza Rahadian, Agus Kuncoro, Endhita, Rio Dewanto, and Hengky Sulaeman. The film focuses around Indonesia\\'s religious pluralism, which often results in conflict between different beliefs, represented in a plot that revolves around the interactions of three families, one Buddhist, one Muslim, and one Catholic. After undergoing numerous hardships and the deaths of several family members in religious violence, they are reconciled.\\nBased on Bramantyo\\'s experiences as a mixed-race child, ? was meant to counter the portrayal of Islam as a \"radical religion\". Owing to the film\\'s theme of religious pluralism and controversial subject matter, Bramantyo had difficulty finding backing. Eventually, Mahaka Pictures put forth Rp 5 billion ($600,000) to fund the production. Filming began on 5 January 2011 in Semarang.\\nReleased on 7 April 2011, ? was a critical and commercial success: it received favourable reviews and was viewed by more than 550,000 people. Screened internationally, it was nominated for nine Citra Awards at the 2011 Indonesian Film Festival, winning one. Several Indonesian Muslim groups, including the conservative Indonesian Ulema Council and the extremist Islamic Defenders Front, protested against the film because of its pluralist message.']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Load the JSON data\n",
    "json_file_path = os.path.join('wiki_corpus.json')\n",
    "\n",
    "with open(json_file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# We'll inspect the first record to understand its structure\n",
    "first_record = data[0] if isinstance(data, list) and len(data) > 0 else {}\n",
    "\n",
    "first_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b19495c5-30d0-4500-bef3-3030688dd246",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_contents = [article[1] for article in data if len(article) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "020bfef8-16c8-4489-9076-93af759123f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/dreampy/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.007*\"two\" + 0.005*\"first\" + 0.004*\"new\" + 0.004*\"would\"')\n",
      "(1, '0.005*\"isbn\" + 0.004*\"also\" + 0.004*\"may\" + 0.004*\"used\"')\n",
      "(2, '0.011*\"first\" + 0.008*\"film\" + 0.007*\"game\" + 0.006*\"world\"')\n",
      "(3, '0.005*\"would\" + 0.005*\"also\" + 0.004*\"new\" + 0.004*\"first\"')\n",
      "(4, '0.010*\"army\" + 0.010*\"battle\" + 0.009*\"german\" + 0.009*\"fleet\"')\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "import gensim\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Assuming article_contents is a list of strings, where each string is an article\n",
    "# Preprocess the text data\n",
    "stop_words = stopwords.words('english')\n",
    "texts = [[word for word in document.lower().split() if word not in stop_words]\n",
    "         for document in article_contents]\n",
    "\n",
    "# Create a dictionary representation of the documents\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "\n",
    "# Convert dictionary to a bag of words corpus\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# Apply LDA\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary, num_topics=5, random_state=100, update_every=1, chunksize=100, passes=10, alpha='auto', per_word_topics=True)\n",
    "\n",
    "# View the topics\n",
    "topics = lda_model.print_topics(num_words=4)\n",
    "for topic in topics:\n",
    "    print(topic)\n",
    "\n",
    "###process was slow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93daa80-2b79-472e-abbc-66643cf8d16d",
   "metadata": {},
   "source": [
    "Using MultiCore module from gensin.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "107062b3-f7dc-4b5d-83af-33491dca5468",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/dreampy/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.021*\"isbn\" + 0.007*\"press.\" + 0.007*\"university\" + 0.006*\"new\"')\n",
      "(1, '0.004*\"would\" + 0.003*\"first\" + 0.003*\"new\" + 0.003*\"also\"')\n",
      "(2, '0.004*\"also\" + 0.004*\"one\" + 0.003*\"first\" + 0.003*\"two\"')\n",
      "(3, '0.010*\"first\" + 0.006*\"team\" + 0.005*\"two\" + 0.005*\"second\"')\n",
      "(4, '0.004*\"two\" + 0.004*\"north\" + 0.003*\"river\" + 0.003*\"south\"')\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "from gensim.models import LdaMulticore\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Preprocess the text data\n",
    "stop_words = stopwords.words('english')\n",
    "texts = [[word for word in document.lower().split() if word not in stop_words]\n",
    "         for document in article_contents]\n",
    "\n",
    "# Create a dictionary representation of the documents\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "\n",
    "# Convert dictionary to a bag of words corpus\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# Apply LDA using LdaMulticore\n",
    "lda_model = LdaMulticore(corpus=corpus, id2word=dictionary, num_topics=5, random_state=100, chunksize=100, passes=10, workers=None, alpha='symmetric', per_word_topics=True)\n",
    "\n",
    "# View the topics\n",
    "topics = lda_model.print_topics(num_words=4)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bc145c7-f987-4488-b002-56b1fce11735",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Extend the stopwords list with custom uninformative words\n",
    "custom_stopwords = ['also', 'one', 'two', 'first', 'new', 'would', 'many', 'may', 'in', 'the','used']\n",
    "stop_words.update(custom_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14d3730f-2dd2-491e-985b-1c16d07f4b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [[word for word in document.lower().split() if word not in stop_words]\n",
    "         for document in article_contents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "147cc37d-44b4-409f-95ce-aac4e29277f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "\n",
    "# Create a new dictionary representation of the documents\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "\n",
    "# Filter out extremes to remove additional noise\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "\n",
    "# Convert the updated dictionary to a bag of words corpus\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01a23cec-23b3-4e96-81fe-3fe5260596c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.006*\"united\" + 0.005*\"state\" + 0.005*\"government\" + 0.005*\"president\" + 0.005*\"states\" + 0.004*\"national\" + 0.003*\"storm\" + 0.003*\"party\" + 0.003*\"federal\" + 0.003*\"tropical\"')\n",
      "(1, '0.006*\"species\" + 0.005*\"found\" + 0.004*\"known\" + 0.003*\"large\" + 0.003*\"around\" + 0.002*\"small\" + 0.002*\"similar\" + 0.002*\"years\" + 0.002*\"although\" + 0.002*\"often\"')\n",
      "(2, '0.004*\"isbn\" + 0.003*\"work\" + 0.003*\"\"the\" + 0.003*\"wrote\" + 0.003*\"later\" + 0.003*\"john\" + 0.003*\"published\" + 0.003*\"university\" + 0.003*\"became\" + 0.002*\"book\"')\n",
      "(3, '0.008*\"army\" + 0.007*\"force\" + 0.007*\"air\" + 0.006*\"german\" + 0.006*\"japanese\" + 0.006*\"battle\" + 0.005*\"british\" + 0.005*\"forces\" + 0.005*\"attack\" + 0.005*\"division\"')\n",
      "(4, '0.004*\"king\" + 0.004*\"war\" + 0.004*\"french\" + 0.003*\"royal\" + 0.003*\"british\" + 0.003*\"military\" + 0.002*\"became\" + 0.002*\"de\" + 0.002*\"english\" + 0.002*\"later\"')\n",
      "(5, '0.009*\"league\" + 0.009*\"club\" + 0.007*\"team\" + 0.007*\"second\" + 0.007*\"cup\" + 0.006*\"football\" + 0.006*\"match\" + 0.005*\"season\" + 0.005*\"final\" + 0.004*\"world\"')\n",
      "(6, '0.009*\"1\" + 0.008*\"2\" + 0.008*\"{\\\\displaystyle\" + 0.008*\"=\" + 0.007*\"+\" + 0.006*\"number\" + 0.005*\"theory\" + 0.005*\"x\" + 0.004*\"group\" + 0.004*\"b\"')\n",
      "(7, '0.003*\"ship\" + 0.003*\"built\" + 0.003*\"north\" + 0.003*\"park\" + 0.003*\"river\" + 0.003*\"along\" + 0.003*\"south\" + 0.003*\"us\" + 0.003*\"three\" + 0.002*\"m)\"')\n",
      "(8, '0.008*\"team\" + 0.006*\"played\" + 0.006*\"second\" + 0.006*\"game\" + 0.005*\"season\" + 0.005*\"three\" + 0.004*\"match\" + 0.004*\"world\" + 0.004*\"test\" + 0.004*\"took\"')\n",
      "(9, '0.008*\"film\" + 0.006*\"game\" + 0.005*\"music\" + 0.005*\"released\" + 0.004*\"album\" + 0.004*\"song\" + 0.003*\"said\" + 0.003*\"best\" + 0.003*\"series\" + 0.003*\"video\"')\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import LdaMulticore\n",
    "\n",
    "# Apply LDA using LdaMulticore with the refined corpus\n",
    "lda_model = LdaMulticore(corpus=corpus, id2word=dictionary, num_topics=10, random_state=100, chunksize=100, passes=10, workers=None, alpha='symmetric', per_word_topics=True)\n",
    "\n",
    "# View topics\n",
    "topics = lda_model.print_topics(num_words=10)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95be65aa-b6e3-4bd8-ac39-b8d1f4e5f6b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
